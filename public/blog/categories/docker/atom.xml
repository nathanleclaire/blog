<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: docker | nathan leclaire]]></title>
  <link href="http://nathanleclaire.com/blog/categories/docker/atom.xml" rel="self"/>
  <link href="http://nathanleclaire.com/"/>
  <updated>2014-09-29T03:20:27+00:00</updated>
  <id>http://nathanleclaire.com/</id>
  <author>
    <name><![CDATA[Nathan LeClaire]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Automagical Deploys from Docker Hub]]></title>
    <link href="http://nathanleclaire.com/blog/2014/08/17/automagical-deploys-from-docker-hub/"/>
    <updated>2014-08-17T05:52:12+00:00</updated>
    <id>http://nathanleclaire.com/blog/2014/08/17/automagical-deploys-from-docker-hub</id>
    <content type="html"><![CDATA[<blockquote><p>I want the speed and other advantages of a static site generator, but with the flexibility of a database-backed CMS.</p></blockquote>

<p><img src="https://nathanleclaire.com/images/automagic-dockerhub/hub.png" alt="" /></p>

<h1>I want performance, flexibility, <em>and</em> ease of maintenance.</h1>

<p>From cars to computers, getting both flexibility and performance all too often requires a carefully weighed set of trade-offs. Generating content for your readers and fans on the web is no exception. On the one hand, techies have recently embraced static site generators such as Jekyll, and for good reason, as these systems provide a lot of advantages (e.g., deploying straight to Github pages, high performance, and ease of keeping your content in version control). However, they are not without their own challenges such as steep learning curves and slow, cumbersome workflows.</p>

<p>On the other hand, flexible, database-backed content management system such as WordPress can be a better choice in some situations. It’s very nice to have the flexibility to allow non-technical people to edit and update content, and for authors to edit online from anywhere without needing a special suite of software and skills. However, CMSs such as WordPress can also be slow, temperamental, and hard to optimize.</p>

<p>Lately, I’ve been trying to find a good balance for my website. Currently, it takes the techie-approved approach: serving static pages via Jekyll. There are lots of things to recommend this approach. I LOVE that people from the community can make pull requests to the site from Github, which has helped me clean it up tremendously. I also value the performance and general ease of maintenance of just serving up static files using Nginx. However, using Jekyll (especially on new computers) can be slow and cumbersome — my stack is based on Octopress and it gives me a lot of heartache due to my noob status in the Ruby ecosystem and because of some not-so-great design decisions I made early on. Additionally, if I merge in a minor change on Github, then I have to fetch the changes to a local computer where Octopress has been set up to perform correctly, re-generate the site using some <code>rake</code> commands and then deploy it again. Not immensely difficult, but not trivial either, and if I am catching small mistakes every day and I want to keep the blog in sync instead of letting it slip, the time to regenerate and re-deploy the site starts to add up quickly. Usually I just let things slip, including keeping the changes up to date on Github.</p>

<p>Additionally, Github’s online markdown editor is <strong>nice</strong> (and fast), and I wouldn’t mind writing whole articles on there from time to time. If I could write using only Github and deploy on commit, a world of possibilities would open up. Yes there is <a href="https://help.github.com/articles/using-jekyll-with-pages">Github Pages</a>, but if I decide to switch static site generators later on I am hosed (plus, I want to eventually finish migrating to <a href="https://github.com/spf13/hugo">hugo</a>).</p>

<h1>Game on.</h1>

<p>So what to do? Well, lately I’ve been thinking that I could reduce a lot of pain by chaining together some automation systems and deploying directly from an automated build on <a href="http://hub.docker.com">Docker Hub</a> by using the great <a href="https://docs.docker.com/docker-hub/builds/#webhooks">Web Hooks</a> feature. This would allow me to trigger a re-build and re-deploy of the blog whenever there is a change in source control on master, and it would all run asynchronously without needing my attention. Better still, this technique could be applied generally to other stacks and other static site generators, letting anyone roll out a solution that fits their needs no matter what they’re building.</p>

<p>To accomplish this, I did the following:</p>

<ol>
<li>Built a <code>Dockerfile</code> to compile the latest static site from source using our chosen stack (Octopress in my case)</li>
<li>Set up an automated build on Docker Hub which will re-build the image from scratch whenever a change is made on Github (including merges and the online editor)</li>
<li>Used Docker Hub’s Web Hooks to make a <code>POST</code> request to a small <a href="https://github.com/cpuguy83/dockerhub-webhook-listener">“hook listener” server</a> running on my Linode which re-deploys the new image (props to <a href="https://github.com/cpuguy83">cpuguy83</a> for helping me with this)</li>
</ol>


<h2>Step 1: Build a <code>Dockerfile</code> for our static site generator</h2>

<p>This is my Dockerfile for this Octopress build, it installs dependencies and then creates the site itself:</p>

<pre>
from debian:wheezy

run apt-get update && \
    apt-get install -y curl build-essential

run apt-get install -y ruby1.9.3
run apt-get install -y lsb-release && \
    curl -sL https://deb.nodesource.com/setup | bash
run apt-get install -y nodejs npm
run apt-get install -y nginx
run gem install bundler

add Gemfile /blog/Gemfile
workdir /blog
run bundle install -j8

add . /blog

run rake install['pageburner'] && rake generate
run rm /etc/nginx/sites-available/default
add nginx/nathanleclaire.com /etc/nginx/sites-available/nathanleclaire.com
run ln -s /etc/nginx/sites-available/nathanleclaire.com /etc/nginx/sites-enabled/nathanleclaire.com

run echo "daemon off;" >>/etc/nginx/nginx.conf

expose 80

cmd ["service", "nginx", "start"]
</pre>


<p>Apparently, Jekyll has a Node.js dependency these days. Who knew? (Side note: Writing my Dockerfiles in all lowercase like this makes me feel like e e cummings. A really geeky e e cummings.)</p>

<p>This Dockerfile is really cool because the <code>bundle install</code> gets cached as long as the Gemfile doesn’t get changed. So, the only part that takes a non-trivial amount of time during the <code>docker build</code> of the image is the <code>rake generate</code> command that spits out the final static site, so the whole process runs quite quickly (unfortunately, though, Highland, Docker’s automated build robot, doesn’t cache builds).</p>

<p>I would love to see some more of these for various static site generating stacks, and I intend to contribute just a vanilla Octopress / Jekyll one at some point soon.</p>

<p>Octopress is pretty finicky about only working with Ruby 1.9.3, so I was fortunate to be able to find a Debian package that fulfills those requirements. The static files get served up with nginx on port 80 of the container (which I just proxy to the host for now), which works well enough for my purposes. In fact, I just have all the gzip and other per-site (caching headers etc.) settings in the nginx config in the container, so I can deploy that stuff this way too (just change the source in the repo and push to Github!). I like this kind of high-level-ops knowledge PaaS fusion mutated weirdness. Yum.</p>

<p>This approach cuts my “native” sites-available file for the websites down to something like:</p>

<pre>server {
  server_name nathanleclaire.com;

  location / {
       proxy_pass http://localhost:8000;
  }

  location /hubhook {
      proxy_pass https://localhost:3000;
  }
}
</pre>


<p>The <code>hubhook</code> is some proxy-matic goodness, which farms out the task to re-deploy the site to a simple but effective “Docker Hub Listener” worker that my colleague Brian Goff originally wrote (and which I twisted to my own nefarious purposes, muahaha). Okay, on to the next steps.</p>

<h2>Step 2: Set up Automated Build for this repo on Docker Hub</h2>

<p>This step is crucial, and really illustrates the power and flexibility of Hub’s automated builds (which if you haven’t tried them already, you <em>totally should</em>). When a change (commit, merge or otherwise) hits the <code>dockerize</code> branch on Github (though it could be any branch, and eventually it will be master for me), it triggers a re-build of the images with the most up-to-date Dockerfile. This means that new articles I have written or content that I have added will be re-built asynchronously by Highland without needing any attention from me. So, even if I merge in a small revision from another user on Github or make a quick edit with the online editor, the site will be rebuilt from source (which is mostly Markdown files and a “theme” template). Note that automated builds work with Bitbucket too if you prefer Bitbucket!!</p>

<p>And, critically, this method takes advantage of a powerful Docker Hub feature called Web Hooks which allows you to make a <code>POST</code> request to the endpoint of your choice whenever a new build is complete. This is what I use to re-deploy the website.</p>

<h2>Step 3: Post to the hook listener server and re-deploy!</h2>

<p>I had been kicking around the idea of implementing something like this for a while, but I was missing a piece. I had no server to listen for the request from Docker Hub when the build was completed. Then, serendipitously, my colleague Brian Goff (also known as super-helpful community member <a href="https://github.com/cpuguy83">cpuguy83</a>) demoed a “webhook listener” that was the very thing I was thinking of writing myself (only his was better thought out, to be be honest). It’s a tiny little Golang program which allows you to register handlers that run when the hook hits, and which has support for both self-signed SSL (so you can send the request with encryption / <code>https</code> from Docker Hub) and for API keys (so that even if black-hats know the endpoint to hit, they won’t know the API key to pass to actually get it to do anything).</p>

<p>Link to the repo here:</p>

<ul>
<li><a href="https://github.com/cpuguy83/dockerhub-webhook-listener">https://github.com/cpuguy83/dockerhub-webhook-listener</a></li>
</ul>


<p>To get it to work, I generated an OpenSSL key and cert (which I linked to in a <code>config.ini</code> file passed to Brian’s server program).</p>

<p>I wrote this script to automate that key/cert generation:</p>

<pre>#!/bin/bash

openssl genrsa -des3 -out server.key 1024 && \
  openssl req -new -key server.key -out server.csr && \
  cp server.key server.key.org && \
  openssl rsa -in server.key.org -out server.key && \
  openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt
</pre>


<p>Then I generated a random API key and also added it to the config file. So, in the end, the <code>config.ini</code> file that I use lives in the same directory as the dockerhub-webhook-listener binary and it looks like this:</p>

<pre>[apiKeys]
key = bigLongRandomApiKeyString

[tls]
key = ../server.key
cert = ../server.crt
</pre>


<p>Lastly, I wrote a simple shell script to run whenever the hub hook listener received a valid request, and wrote a Go handler to invoke it from Brian’s server program.</p>

<p>The shell script looks like this:</p>

<pre>#!/bin/bash

sudo docker pull nathanleclaire/octoblog:latest
docker stop blog
docker rm blog
docker run --name blog -d -p 8000:80 nathanleclaire/octoblog
</pre>


<p>Just keeping it simple for now.</p>

<p>The Go code looks like this:</p>

<pre><code class="go">func reloadHandler(msg HubMessage) {
  log.Println("received message to reload ...")
  out, err := exec.Command("../reload.sh").Output()
  if err != nil {
    log.Println("ERROR EXECUTING COMMAND IN RELOAD HANDLER!!")
    log.Println(err)
    return
  }
  log.Println("output of reload.sh is", string(out))
}
</code></pre>

<p>As you can see, there’s nothing too fancy here. It’s just Plain Old Golang and Shell Script. In fact, it could be a lot more sophisticated, but this works just fine- which is part of what pleases me a lot about this setup.</p>

<p>Finally, we use the Docker Hub webhooks configuration to make the <code>POST</code> request to the endpoint exposed on the public Internet by this middleware server. In my case, I added an endpoint called <code>/hubhook</code> to my nginx configuration that proxies the outside request to the dockerhub-webhook-listener running on <code>localhost:3000</code>. The API key is passed as a query string parameter, i.e., the request is to <code>https://nathanleclaire.com/hubhook?apikey=bigLongRandomApiKeyString</code>.</p>

<p>So, pieced together, this is how this all works:</p>

<ol>
<li>Commit hits Github</li>
<li>Docker Hub builds image</li>
<li>Docker Hub hits middleware server with hook</li>
<li>Server pulls image, and restarts the server</li>
</ol>


<h1>Automagical.</h1>

<p>Now my deploys are launched seamlessly from source control push. I really enjoy this. Now that everything is set up, it will work smoothly without needing any manual intervention from me (though I need additional logging and monitoring around the systems involved to ensure their uptime and successful operation, in particular,&amp; the hub hook listener – <em>oh god, am I slowly turning into a sysadmin? NAH</em>)</p>

<p>There is still a lot of room for improvement in this setup (specifically around how Docker images get moved around and the ability to extract build artifacts from them, both of which should improve in the future), but I hope I have stimulated your imagination with this setup. I really envision the future of application portability as being able to work and edit apps anywhere, without needing your hand-crafted pet environment, and being able to rapidly deploy them without having to painstakingly sit through every step of the process yourself.</p>

<p>So go forth and create cool (Dockerized) stuff!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[10 Docker Tips and Tricks That Will Make You Sing A Whale Song of Joy]]></title>
    <link href="http://nathanleclaire.com/blog/2014/07/12/10-docker-tips-and-tricks-that-will-make-you-sing-a-whale-song-of-joy/"/>
    <updated>2014-07-12T17:35:00+00:00</updated>
    <id>http://nathanleclaire.com/blog/2014/07/12/10-docker-tips-and-tricks-that-will-make-you-sing-a-whale-song-of-joy</id>
    <content type="html"><![CDATA[<p><img src="/images/dockertips/humpback.jpg"></p>

<h1>docker run -it nathanleclaire/article</h1>

<p>As mentioned in a previous post I just started a shiny new job at Docker Inc. and I&#8217;ve been accumulating all sorts of good Docker tips and tricks.  I think there is probably demand for them in the community, where just the sheer amount of information about Docker to take in is very overwhelming.  Once you&#8217;ve mastered the basics, the creative possibilites are endless, and already my mind has been blown by what some of the folks I work with have come up with.  Just like I mentioned in <a href="http://nathanleclaire.com/blog/2014/03/22/what-is-this-docker-thing-that-everyone-is-so-hyped-about/">this post</a>, the Cambrian explosion of creativity it&#8217;s provoking is extremely exciting.</p>

<p>So I&#8217;m going to share some of my favorite tips and tricks with you guys.  Ready?</p>

<p>The 10 tips and tricks are:</p>

<ol>
<li>Run it on a VPS for extra speed</li>
<li>Bind mount the docker socket on docker run</li>
<li>Use containers as highly disposable dev environments</li>
<li>bash is your friend</li>
<li>Insta-nyan</li>
<li>Edit <code>/etc/hosts/</code> with the <code>boot2docker</code> IP address on OSX</li>
<li><code>docker inspect -f</code> voodoo</li>
<li>Super easy terminals in-browser with wetty</li>
<li>nsenter</li>
<li>&#35;docker</li>
</ol>


<p>Alright, let&#8217;s do this!</p>

<h2>Run it on a VPS for extra speed</h2>

<p><img src="/images/dockertips/vps.jpeg"></p>

<p>This one&#8217;s pretty straightforward.  If you run Docker on <a href="http://digitalocean.com">Digital Ocean</a> or <a href="http://linode.com">Linode</a> you can get way better bandwidth on pulls and pushes if, like me, your home internet&#8217;s bandwidth is pretty lacking.  I get around 50mbps download with Comcast, on my Linode my speed tests run an order of magnitude faster than that.</p>

<p>So if you have the need for speed, consider investing in a VPS for your own personal Docker playground.</p>

<h2>Bind mount the docker socket on docker run</h2>

<p>What if you want to do Docker-ey things inside of a container but you don&#8217;t want to go full Docker in Docker (dind) and run in <code>--privileged</code> mode?  Well, you can use a base image that has the Docker client installed and bind-mount your Docker socket with <code>-v</code>.</p>

<pre><code class="sh">docker run -it -v /var/run/docker.sock:/var/run/docker.sock nathanleclaire/devbox
</code></pre>

<p>Now you can send docker commands to the same instance of the docker daemon you are using on the host - inside your container!</p>

<p>This is really fun because it gives you all the advantages of being able to mess around with Docker containers on the host, with the flexibility and ephemerality of containers.  Which leads into my next tip&#8230;.</p>

<h2>Use containers as highly disposable dev environments</h2>

<p><img src="/images/dockertips/devenv.gif"></p>

<p>How many times have you needed to quickly isolate an issue to see if it was related to certain factors in particular, and nothing else?  Or just wanted to pop onto a new branch, make some changes and experiment a little bit with what you have running/installed in your environment, without accidentally screwing something up big time?</p>

<p>Docker allows you to do this in a a portable way.</p>

<p>Simply create a Dockerfile that defines your ideal development environment on the CLI (including ack, autojump, Go, etc. if you like those - whatever you need) and kick up a new instance of that image whenever you want to pop into a totally new box and try some stuff out.  For instance, here&#8217;s <a href="https://github.com/shykes">Solomon&#8217;s</a>.</p>

<pre><code>FROM ubuntu:14.04

RUN apt-get update -y
RUN apt-get install -y mercurial
RUN apt-get install -y git
RUN apt-get install -y python
RUN apt-get install -y curl
RUN apt-get install -y vim
RUN apt-get install -y strace
RUN apt-get install -y diffstat
RUN apt-get install -y pkg-config
RUN apt-get install -y cmake
RUN apt-get install -y build-essential
RUN apt-get install -y tcpdump
RUN apt-get install -y screen

# Install go
RUN curl https://go.googlecode.com/files/go1.2.1.linux-amd64.tar.gz | tar -C /usr/local -zx
ENV GOROOT /usr/local/go
ENV PATH /usr/local/go/bin:$PATH

# Setup home environment
RUN useradd dev
RUN mkdir /home/dev &amp;&amp; chown -R dev: /home/dev
RUN mkdir -p /home/dev/go /home/dev/bin /home/dev/lib /home/dev/include
ENV PATH /home/dev/bin:$PATH
ENV PKG_CONFIG_PATH /home/dev/lib/pkgconfig
ENV LD_LIBRARY_PATH /home/dev/lib
ENV GOPATH /home/dev/go:$GOPATH

RUN go get github.com/dotcloud/gordon/pulls

# Create a shared data volume
# We need to create an empty file, otherwise the volume will
# belong to root.
# This is probably a Docker bug.
RUN mkdir /var/shared/
RUN touch /var/shared/placeholder
RUN chown -R dev:dev /var/shared
VOLUME /var/shared

WORKDIR /home/dev
ENV HOME /home/dev
ADD vimrc /home/dev/.vimrc
ADD vim /home/dev/.vim
ADD bash_profile /home/dev/.bash_profile
ADD gitconfig /home/dev/.gitconfig

# Link in shared parts of the home directory
RUN ln -s /var/shared/.ssh
RUN ln -s /var/shared/.bash_history
RUN ln -s /var/shared/.maintainercfg

RUN chown -R dev: /home/dev
USER dev
</code></pre>

<p>Especially deadly if you use vim/emacs as your editor <code>;)</code>.  You can use <code>/bin/bash</code> as your <code>CMD</code> and <code>docker run -it my/devbox</code> right into a shell.</p>

<p>You can also bind-mount the Docker client binary and socket (as mentioned above) inside the container when you run it to have access to the host&#8217;s Docker daemon for container antics!</p>

<p>Likewise you can bootstrap a development environment on a new computer easily this way.  Just install docker and download your dev box image!</p>

<h2>bash is your friend</h2>

<p>Or &#8220;the shell is your friend&#8221;.  Sorry <code>zsh</code> and <code>fish</code> users.</p>

<p>Just like many of you have aliases for <code>git</code> to save keystrokes, you&#8217;ll likely want to create little shortcuts for youself if you start to use Docker heavily.  Just add these to your <code>~/.bashrc</code> or equivalent and off you go.</p>

<p>There are some obvious ones:</p>

<pre><code class="sh">alias drm="docker rm"
alias dps="docker ps"
</code></pre>

<p>Basically I will add one of these whenever I find myself typing the same command over and over.  Like you do :D</p>

<p>You can also mix and match in all kinds of fun ways.  You can do</p>

<pre><code class="sh">$ drm -f $(docker ps -aq)
</code></pre>

<p>To remove all containers, for instance (including those which are running).  Or:</p>

<pre><code>function da () {
    docker start $1 &amp;&amp; docker attach $1
}
</code></pre>

<p>to start a stopped conatiner and attach to it.</p>

<p>I created a fun one to enable my rapid-bash-container-prompt habit mentioned in the previous tip:</p>

<pre><code>function newbox () {
    docker run --name $1 --volumes-from=volume_container -it -v /var/run/docker.sock:/var/run/docker.sock -e BOX_NAME=$1 nathanleclaire/devbox
}
</code></pre>

<h2>Insta-nyan</h2>

<p><img src="/images/dockertips/nyan.png" title="Let&#8217;s face it, who doesn&#8217;t love this?" ></p>

<p>Pretty simple.  You want a nyan-cat in your terminal, you have docker, and you need only one command to activate the goodness.</p>

<pre><code>docker run -it supertest2014/nyan
</code></pre>

<h2>Edit <code>/etc/hosts/</code> with the <code>boot2docker</code> IP address on OSX</h2>

<p><img src="/images/dockertips/hacking.png" title="This is what hacking looks like." ></p>

<p>The newest (read: BEST) versions of <a href="https://github.com/boot2docker/boot2docker">boot2docker</a> include a host-only network where you can access ports exposed by containers using the boot2docker virtual machine&#8217;s IP address. The <code>boot2docker ip</code> command makes access to this value easy.  However, usually it is simply <code>192.168.59.103</code>.  I find this specific address a little hard to remember and cumbersome to type, so I add an entry to my <code>/etc/hosts</code> file for easy access of <code>boot2docker:port</code> when I&#8217;m running applications that expose ports with Docker.  It&#8217;s handy, give it a shot!</p>

<p><strong>Note</strong>: Do remember that it is possible for the boot2docker VM&#8217;s IP address to change, so make sure to check that if you are encountering network issues using this shortcut.  If you are not doing something that would mess with your network configuration (setting up and tearing down multiple virtual machines including boot2docker&#8217;s, etc.), though, you will likely not encounter this issues.</p>

<p>While you&#8217;re at it you should probably tweet <a href="http://twitter.com/SvenDowideit">@SvenDowideit</a> and thank him for his work on boot2docker, since he is an absolute champ for delivering, maintaining, and documenting it.  ;)</p>

<h2><code>docker inspect -f</code> voodoo</h2>

<p>You can do all sorts of awesome flexible things with the <code>docker inspect</code> command&#8217;s <code>-f</code> (or <code>--format</code>) flag if you&#8217;re willing to learn a little bit about <a href="http://golang.org/pkg/text/template/">Go templates</a>.</p>

<p>Normally <code>docker inspect $ID</code> outputs a big JSON dump, and you access individual properties with templating like:</p>

<p>
<code>
docker inspect -f '{{ .NetworkSettings.IPAddress }}' $ID
</code>
</p>

<p>The argument to <code>-f</code> is a Go template.  If you try something like:</p>

<p>
<code>
$ docker inspect -f '{{ .NetworkSettings }}' $ID
map[Bridge:docker0 Gateway:172.17.42.1 IPAddress:172.17.0.4 IPPrefixLen:16 PortMapping:&lt;nil&gt; Ports:map[5000/tcp:[map[HostIp:0.0.0.0 HostPort:5000]]]]
</code>
</p>

<p>You will not get JSON since Go will actually just dump the data type that Docker is marshalling into JSON for the output you see without <code>-f</code>.  But you can do:</p>

<p>
<code>
$ docker inspect -f '{{ json .NetworkSettings }}' $ID
{"Bridge":"docker0","Gateway":"172.17.42.1","IPAddress":"172.17.0.4","IPPrefixLen":16,"PortMapping":null,"Ports":{"5000/tcp":[{"HostIp":"0.0.0.0","HostPort":"5000"}]}}
</code>
</p>

<p>To get JSON!  And to prettify it, you can pipe it into a Python builtin:</p>

<p>
<code>
$ docker inspect -f '{{ json .NetworkSettings }}' $ID | python -mjson.tool
{
    "Bridge": "docker0",
    "Gateway": "172.17.42.1",
    "IPAddress": "172.17.0.4",
    "IPPrefixLen": 16,
    "PortMapping": null,
    "Ports": {
        "5000/tcp": [
            {
                "HostIp": "0.0.0.0",
                "HostPort": "5000"
            }
        ]
    }
}
</code>
</p>

<p>You can also do other fun tricks like access object properties which have non-alphanumeric keys.  Helps to know some Go :P</p>

<p>
<code>
docker inspect -f '{{ index .Volumes "/host/path" }}' $ID
</code>
</p>

<p>This is a very powerful tool for quickly extracting information about your running containers, and is extremely helpful for troubleshooting because it provides a ton of detail.</p>

<h2>Super easy terminals in-browser with wetty</h2>

<p>I really foresee people making extremely FUN web applications with this kind of functionality.  You can spin up a container which is running an instance of <a href="https://github.com/krishnasrinivas/wetty">wetty</a> (a JavaScript-powered in-browser terminal emulator).</p>

<p>Try it for yourself with:</p>

<pre><code>docker run -p 3000:3000 -d nathanleclaire/wetty
</code></pre>

<p><img src="/images/dockertips/wetty.png"></p>

<p>Wetty only works in Chrome unfortunately, but there are other JavaScript terminal emulators begging to be Dockerized and if you are using it for a presentation or something (imagine embedding interactive CLI snapshots in your Reveal.js slideshow - nice) you control the browser anyway.  Now you can embed isolated terminal applications in web applications wherever you want, and you control the environment in which they execute with an excruciating amount of detail.  No pollution from host to container, and vice versa.</p>

<p>The creative possibilites of this are just mind-boggling to me.  I REALLY want to see someone make a version of <a href="http://typeracer.com">TypeRacer</a> where you compete with other contestants in real time to type code into vim or emacs as quickly as possible.  That would be pure awesome.  Or a real-time coding challenge where your code competes with other code in an arena for dominance ala <a href="http://www.corewars.org/">Core Wars</a>.</p>

<h2>nsenter</h2>

<p><a href="http://twitter.com/jpetazzo">Jerome</a> wrote an opinionated article a few weeks ago that shook things up a bit.  In it, he argues that you should not need to run <code>sshd</code> (daemon for getting a remote terminal prompt) in your containers and, in fact, if you are doing so you are violating the Docker philosophy (one concern per container).  It&#8217;s a good read, and he mentions <code>nsenter</code> as a fun trick to get a prompt inside of containers which have already been initialized with a process.</p>

<p>See <a href="http://jpetazzo.github.io/2014/06/23/docker-ssh-considered-evil/">here</a> or <a href="http://www.sebastien-han.fr/blog/2014/01/27/access-a-container-without-ssh/">here</a> to learn how to do it.</p>

<h2>#docker</h2>

<p>I&#8217;m not talking about the hashtag!!  I&#8217;m talking about the channel on Freenode on IRC.  It&#8217;s hands-down the best place to meet with fellow Dockers online, ask questions (all levels welcome!), and seek truly excellent expertise.  At any given time there are about 1000 people or more sitting in, and it&#8217;s a great community as well as resource.  Seriously, if you&#8217;ve never tried it before, go check it out.  I know IRC can be scary if you&#8217;re not accustomed to using it, but the effort of setting it up and learning to use it a bit will pay huge dividends for you in terms of knowledge gleaned.  I guarantee it.  So if you haven&#8217;t come to hang out with us on IRC yet, do it!</p>

<p>To join:</p>

<ol>
<li>Download an IRC Client such as <a href="http://limechat.net/mac/">LimeChat</a></li>
<li>Connect to the <code>irc.freenode.net</code> network</li>
<li>Join the <code>#docker</code> channel</li>
</ol>


<p>Welcome!</p>

<h1>Conclude</h1>

<p>That&#8217;s all for now folks, I hope you&#8217;ve learned a bit and you have all sorts of great ideas burning in your head about Docker!!  Enjoy it, join the conversation around it, and above all <strong>BE CREATIVE</strong>.</p>

<p>Until next time, stay sassy Internet.  And consider <a href="http://nathanleclaire.com">signing up for my mailing list</a>.</p>

<ul>
<li>Nathan</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[What is this Docker thing that everyone is so hyped about?]]></title>
    <link href="http://nathanleclaire.com/blog/2014/03/22/what-is-this-docker-thing-that-everyone-is-so-hyped-about/"/>
    <updated>2014-03-22T20:38:00+00:00</updated>
    <id>http://nathanleclaire.com/blog/2014/03/22/what-is-this-docker-thing-that-everyone-is-so-hyped-about</id>
    <content type="html"><![CDATA[<p><img src="/images/what-is-docker/moby-dick.jpg" title="Just another day in Devops." ></p>

<h1>Docker</h1>

<p>Approximately one year ago I was browsing <a href="http://news.ycombinator.com">Hacker News</a> and I came across this video:</p>

<div style="text-align: center;">
<iframe style="width: 420px !important;" width="420" height="315" src="//www.youtube.com/embed/wW9CAH9nSLs" frameborder="0" allowfullscreen></iframe>
</div>


<p>I found it profoundly exciting for reasons I could not explain, mostly Solomon&#8217;s infectious enthusiasm and the enthusiasm that the Hacker News commmunity reacted to it with.  When I learned that Docker was being written in <a href="http://golang.org">Go</a> I was even more intruiged.  Especially having played with Go quite a bit, I have a hunch that Go will be a language which dictates the future of the &#8220;cloud&#8221; in a lot of ways.  <a href="http://cloudflare.com">Cloudflare</a>, for instance, has a ton of infrastructure written in Go that powers their CDN and other cool tools they provide such as <a href="https://www.cloudflare.com/railgun">Railgun</a>.  This was definitely a project to keep an eye on.  I mentally dog-eared it.</p>

<p>There was only one problem:  I didn&#8217;t understand what Docker <em>was</em> yet.  There was talk of containers and shipping but I didn&#8217;t understand what it all meant, or what it could be used for.</p>

<p>Then about six months ago, things began to gel and sink in for me.</p>

<h1>The Problem</h1>

<p><img src="/images/what-is-docker/matrix-from-hell.png"></p>

<p>In order to better understand Docker you have to understand the problem it is trying to solve.</p>

<p>Modern day development (I&#8217;ll be focusing on the web here) lives in a world of lots of complexity.  In even the most basic application you are likely to have a back-end language that lives on the server, a front-end language (almost ubiquitously JavaScript) that lives on the client, third-party and in-house libraries for both of these languages to manage, a database, an operating system (often deploying to Linux but developing on God-knows-what OS), and more.  And this is for a <em>basic</em> app!  What if you have utility programs that are written in another language?  What if you have other weird dependencies and requirements?</p>

<p>My point is that this all adds up to a lot of complexity, and worst of all- it is complexity that you have to manage across multiple platforms.  If I got an app up and running on my Macbook, and wanted to deploy to Linux, my options were not great.  If you&#8217;ve ever administrated your own VPS, much less a bare metal server, you know what I mean.  Having to install all of the packages and dependencies that you have in a totally different way is a recipe for headaches and tears.  Getting stuff to production is a completely different ball game from writing it in the first place.  Different technologies on different platforms create a &#8220;Matrix from Hell&#8221; (pictured above) that makes even the most courageous ops person want to set her hair on fire.</p>

<p>Traditionally there have been a variety of solutions that have popped up in response to this, ranging from &#8220;just develop in PHP and FTP is your deploy&#8221; (ew) to <a href="http://heroku.com">Heroku</a> (<code>git push heroku master</code> is your deploy) to virtualization with provisioning (see <a href="http://vagrantup.com">Vagrant</a>).  Vagrant in particular has been gaining a lot of steam lately, for very good reason, and is a great technology (see my post on <a href="http://nathanleclaire.com/blog/2014/02/10/5-reasons-we-won-startup-weekend/">how we won Startup Weekend</a> if you&#8217;re curious why Vagrant was useful to us in that case).  However, virtual machines have several disadvantages as well.  Because the VM software has to simulate actual physical hardware, you take a big performance hit.  They are slow to start up and, especially before Vagrant started to become popular, difficult to get inexperienced developers started on (Download Vagrant and its dependencies and run <code>vagrant up</code> is a lot nicer than going through all of the VirtualBox menus, then provisioning your box manually).</p>

<h1>Containers</h1>

<p><img src="/images/what-is-docker/containers.jpg"></p>

<p><a href="https://linuxcontainers.org/">Containers</a> popped up as a solution to this issue.  They are sort of like virtual machines, but they focus on process isolation and containment instead of emulating a full-fledged physical machine.  The &#8220;guest&#8221; container uses the same kernel as the &#8220;host&#8221; machine (and possibly some other resources as well, but my understanding of this at this time is a little fuzzy).  This allows many of the advantages of virtual machines without some of the aforementioned disadvantages.</p>

<p>Enter <a href="http://docker.io">Docker</a> (from the homepage):</p>

<blockquote><p>Docker is an open-source project to easily create lightweight, portable, self-sufficient containers from any application. The same container that a developer builds and tests on a laptop can run at scale, in production, on VMs, bare metal, OpenStack clusters, public clouds and more.</p></blockquote>

<p><img src="/images/what-is-docker/docker.png"></p>

<p>Docker&#8217;s goal is to provide a software solution that will allow users to &#8220;pack up&#8221; their applications into a standardized container and &#8220;ship it off&#8221; to wherever their heart desires.  A container, once developed, can be deployed anywhere that Docker runs.  They compare these containers to actual <a href="http://en.wikipedia.org/wiki/Containerization">physical shipping containers</a>, pictured above, which revolutionized international trade when it was standardized after World War 2.  From Wikipedia:</p>

<blockquote><p>Containerization dramatically reduced transport costs &#8230; reduced congestion in ports, significantly shortened shipping time, and reduced losses from damage and theft.</p></blockquote>

<p>Sound like benefits that would be nice to have for your business?</p>

<h1>A Cambrian Explosion</h1>

<p><img src="/images/what-is-docker/cambrian.png"></p>

<p>What is really interesting about Docker though, to me personally at least, is the Cambrian Explosion-esque fugue of creativity that it has inspired so far and continues to inspire in people everywhere.  It is being used for things online that aren&#8217;t exactly aligned to its original use case but really hearken to a bold new future of tech.  I know of at least one example where it is being used to make possible a interpreter-by-runnable-code editor for conducting Python interviews.  <a href="http://www.runnable.com">Runnable.com</a> uses Docker to host self-contained executable / editable little code projects where you can look at existing code which you know works, edit it on the fly, and re-run it.  That&#8217;s awesome!</p>

<p>I&#8217;m super optimistic for the future of this technology.</p>

<p>Until next time, stay sassy Internet.</p>

<ul>
<li>Nathan</li>
</ul>

]]></content>
  </entry>
  
</feed>
